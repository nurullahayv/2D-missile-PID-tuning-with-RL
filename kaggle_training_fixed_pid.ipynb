{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfaf Missile Fixed PID Optimization with RL - Kaggle GPU Training\n",
        "\n",
        "Train RL agents to find optimal **FIXED** PID parameters (set once, stay constant).\n",
        "\n",
        "**Difference from Adaptive PID:**\n",
        "- **Fixed PID** (this notebook): RL learns optimal static PID values \u2192 practical, interpretable\n",
        "- **Adaptive PID** (other notebook): RL adjusts PID every step \u2192 advanced, complex\n",
        "\n",
        "**Requirements:**\n",
        "- Kaggle GPU (T4 or P100)\n",
        "- Internet enabled (for pip install)\n",
        "\n",
        "**Training Time:** ~20-30 minutes (500K timesteps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Install dependencies with fixed versions\n",
        "!pip install -q 'numpy<2' gymnasium 'stable-baselines3[extra]' torch tensorboard\n",
        "\n",
        "print(\"\\n\u2713 Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f WARNING: No GPU detected! Training will be slow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Missile PID System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\n\nclass PIDController:\n    \"\"\"Simple PID controller\"\"\"\n    def __init__(self, kp=2.0, ki=0.1, kd=0.5):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.integral = 0.0\n        self.prev_error = 0.0\n\n    def compute(self, error, dt):\n        self.integral += error * dt\n        derivative = (error - self.prev_error) / dt if dt > 0 else 0.0\n        output = self.kp * error + self.ki * self.integral + self.kd * derivative\n        self.prev_error = error\n        return output\n\n    def reset(self):\n        self.integral = 0.0\n        self.prev_error = 0.0\n\n    def set_gains(self, kp, ki, kd):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n\n\nclass Missile:\n    \"\"\"2D Missile with PID guidance\"\"\"\n    def __init__(self, x=0.0, y=0.0, vx=800.0, vy=0.0,\n                 max_speed=1000.0, max_accel=1000.0,\n                 kp=2.0, ki=0.1, kd=0.5):\n        self.x = x\n        self.y = y\n        self.vx = vx\n        self.vy = vy\n        self.max_speed = max_speed\n        self.max_accel = max_accel\n        self.pid = PIDController(kp, ki, kd)\n        self.active = True\n        self.fuel = 1.0\n\n    @property\n    def speed(self):\n        return np.sqrt(self.vx**2 + self.vy**2)\n\n    @property\n    def heading(self):\n        return np.arctan2(self.vy, self.vx)\n\n    def update(self, target_pos, dt):\n        if not self.active:\n            return\n\n        dx = target_pos[0] - self.x\n        dy = target_pos[1] - self.y\n        desired_heading = np.arctan2(dy, dx)\n        error = desired_heading - self.heading\n        error = np.arctan2(np.sin(error), np.cos(error))\n\n        control = self.pid.compute(error, dt)\n        control = np.clip(control, -self.max_accel, self.max_accel)\n\n        if self.speed > 0:\n            perp = np.array([-self.vy, self.vx]) / self.speed\n            self.vx += perp[0] * control * dt\n            self.vy += perp[1] * control * dt\n\n        current_speed = self.speed\n        if current_speed > self.max_speed:\n            scale = self.max_speed / current_speed\n            self.vx *= scale\n            self.vy *= scale\n\n        self.x += self.vx * dt\n        self.y += self.vy * dt\n        self.fuel -= 0.01 * dt\n        \n        if self.fuel <= 0:\n            self.active = False\n\nprint(\"\u2713 Missile system defined\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define Moving Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Target:\n",
        "    \"\"\"Moving target with different maneuver patterns\"\"\"\n",
        "    def __init__(self, x=8000.0, y=5000.0, speed=1000.0, maneuver='straight'):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.speed = speed\n",
        "        self.heading = np.pi\n",
        "        self.maneuver = maneuver\n",
        "        self.time = 0.0\n",
        "\n",
        "    @property\n",
        "    def velocity(self):\n",
        "        vx = self.speed * np.cos(self.heading)\n",
        "        vy = self.speed * np.sin(self.heading)\n",
        "        return np.array([vx, vy])\n",
        "\n",
        "    def update(self, dt, missile_pos=None):\n",
        "        self.time += dt\n",
        "\n",
        "        if self.maneuver == 'straight':\n",
        "            pass\n",
        "        elif self.maneuver == 'circular':\n",
        "            turn_rate = 0.3\n",
        "            self.heading += turn_rate * dt\n",
        "        elif self.maneuver == 'zigzag':\n",
        "            if int(self.time) % 4 < 2:\n",
        "                turn_rate = 0.5\n",
        "            else:\n",
        "                turn_rate = -0.5\n",
        "            self.heading += turn_rate * dt\n",
        "        elif self.maneuver == 'evasive' and missile_pos is not None:\n",
        "            dx = self.x - missile_pos[0]\n",
        "            dy = self.y - missile_pos[1]\n",
        "            distance = np.sqrt(dx**2 + dy**2)\n",
        "            if distance < 3000:\n",
        "                escape_heading = np.arctan2(dy, dx)\n",
        "                heading_diff = escape_heading - self.heading\n",
        "                heading_diff = np.arctan2(np.sin(heading_diff), np.cos(heading_diff))\n",
        "                turn_rate = 0.8 * np.sign(heading_diff)\n",
        "                self.heading += turn_rate * dt\n",
        "\n",
        "        vx = self.speed * np.cos(self.heading)\n",
        "        vy = self.speed * np.sin(self.heading)\n",
        "        self.x += vx * dt\n",
        "        self.y += vy * dt\n",
        "\n",
        "print(\"\u2713 Target system defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Fixed PID Environment \u2b50\n",
        "\n",
        "**Key difference:** Agent sets PID parameters ONCE at episode start, then they stay FIXED."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import gymnasium as gym\nfrom gymnasium import spaces\n\nclass FixedPIDEnv(gym.Env):\n    \"\"\"Environment for learning optimal FIXED PID parameters\"\"\"\n    metadata = {'render_modes': ['human', 'rgb_array'], 'render_fps': 60}\n\n    def __init__(self, map_size=10000.0, hit_radius=50.0, max_steps=500,\n                 dt=0.01, target_maneuver='circular',\n                 missile_speed=1000.0, missile_accel=1000.0, target_speed=1000.0):\n        super().__init__()\n\n        # Action: Direct PID parameter values (set once per episode)\n        self.action_space = spaces.Box(\n            low=np.array([0.1, 0.0, 0.0], dtype=np.float32),\n            high=np.array([10.0, 2.0, 5.0], dtype=np.float32),\n            dtype=np.float32\n        )\n\n        # Observation: No PID values needed (they're fixed)\n        self.observation_space = spaces.Box(\n            low=-np.inf, high=np.inf, shape=(11,), dtype=np.float32\n        )\n\n        self.map_size = map_size\n        self.hit_radius = hit_radius\n        self.max_steps = max_steps\n        self.dt = dt\n        self.target_maneuver = target_maneuver\n        self.missile_speed = missile_speed\n        self.missile_accel = missile_accel\n        self.target_speed = target_speed\n\n        self.missile = None\n        self.target = None\n        self.steps = 0\n        self.fixed_pid_set = False\n\n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed)\n\n        initial_vx = np.random.uniform(0.8 * self.missile_speed, 0.9 * self.missile_speed)\n        self.missile = Missile(\n            x=0.0, y=0.0, vx=initial_vx, vy=0.0,\n            max_speed=self.missile_speed,\n            max_accel=self.missile_accel,\n            kp=2.0, ki=0.1, kd=0.5\n        )\n\n        target_x = np.random.uniform(0.6 * self.map_size, 0.9 * self.map_size)\n        target_y = np.random.uniform(0.3 * self.map_size, 0.7 * self.map_size)\n        self.target = Target(\n            x=target_x, y=target_y,\n            speed=self.target_speed,\n            maneuver=self.target_maneuver\n        )\n\n        self.steps = 0\n        self.fixed_pid_set = False\n\n        return self._get_obs(), {}\n\n    def step(self, action):\n        # On FIRST step: set PID parameters from action\n        if not self.fixed_pid_set:\n            kp = float(action[0])\n            ki = float(action[1])\n            kd = float(action[2])\n            self.missile.pid.kp = kp\n            self.missile.pid.ki = ki\n            self.missile.pid.kd = kd\n            self.fixed_pid_set = True\n\n        # On subsequent steps: action is IGNORED (PID stays fixed)\n\n        # Update simulation\n        self.missile.update(np.array([self.target.x, self.target.y]), self.dt)\n        self.target.update(self.dt, missile_pos=np.array([self.missile.x, self.missile.y]))\n        self.steps += 1\n\n        # Calculate distance\n        dx = self.target.x - self.missile.x\n        dy = self.target.y - self.missile.y\n        distance = np.sqrt(dx**2 + dy**2)\n\n        # Check termination\n        hit = distance < self.hit_radius\n        out_of_bounds = (self.missile.x < -1000 or self.missile.x > self.map_size + 1000 or\n                        self.missile.y < -1000 or self.missile.y > self.map_size + 1000)\n        out_of_fuel = self.missile.fuel <= 0\n        max_steps_reached = self.steps >= self.max_steps\n\n        done = hit or out_of_bounds or out_of_fuel or max_steps_reached\n\n        # Reward calculation\n        reward = -distance / 1000.0\n\n        if hit:\n            reward += 100.0\n            time_bonus = (self.max_steps - self.steps) / 10.0\n            reward += time_bonus\n\n        if (out_of_bounds or out_of_fuel or max_steps_reached) and not hit:\n            reward -= 50.0\n\n        if self.missile.fuel > 0:\n            reward += self.missile.fuel / 10000.0\n\n        info = {\n            'hit': hit,\n            'distance': distance,\n            'steps': self.steps,\n            'pid_kp': self.missile.pid.kp,\n            'pid_ki': self.missile.pid.ki,\n            'pid_kd': self.missile.pid.kd,\n            'fuel': self.missile.fuel\n        }\n\n        return self._get_obs(), reward, done, False, info\n\n    def _get_obs(self):\n        # Missile state\n        m_x = self.missile.x / self.map_size\n        m_y = self.missile.y / self.map_size\n        m_vx = self.missile.vx / self.missile.max_speed\n        m_vy = self.missile.vy / self.missile.max_speed\n\n        # Target state\n        t_x = self.target.x / self.map_size\n        t_y = self.target.y / self.map_size\n        target_vel = self.target.velocity\n        t_vx = target_vel[0] / self.target.speed\n        t_vy = target_vel[1] / self.target.speed\n\n        # Relative info\n        dx = self.target.x - self.missile.x\n        dy = self.target.y - self.missile.y\n        distance = np.sqrt(dx**2 + dy**2) / self.map_size\n\n        # Angle error\n        desired_angle = np.arctan2(dy, dx)\n        current_angle = np.arctan2(self.missile.vy, self.missile.vx)\n        angle_error = desired_angle - current_angle\n        angle_error = np.arctan2(np.sin(angle_error), np.cos(angle_error))\n\n        # Fuel\n        fuel = self.missile.fuel / 1.0\n\n        obs = np.array([\n            m_x, m_y, m_vx, m_vy,\n            t_x, t_y, t_vx, t_vy,\n            distance, angle_error, fuel\n        ], dtype=np.float32)\n\n        return obs\n\nprint(\"\u2713 Fixed PID environment defined\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "ALGORITHM = 'SAC'  # SAC works best for this task\n",
        "TARGET_MANEUVER = 'circular'  # straight, circular, zigzag, evasive\n",
        "TOTAL_TIMESTEPS = 500_000  # 500K timesteps\n",
        "N_ENVS = 1\n",
        "\n",
        "# Speed configuration\n",
        "MISSILE_SPEED = 1000.0  # m/s\n",
        "MISSILE_ACCEL = 1000.0  # m/s\u00b2\n",
        "TARGET_SPEED = 1000.0   # m/s\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Algorithm: {ALGORITHM}\")\n",
        "print(f\"  Target Maneuver: {TARGET_MANEUVER}\")\n",
        "print(f\"  Total Timesteps: {TOTAL_TIMESTEPS:,}\")\n",
        "print(f\"\\n\ud83d\ude80 Speed Config:\")\n",
        "print(f\"  Missile: {MISSILE_SPEED} m/s, {MISSILE_ACCEL} m/s\u00b2\")\n",
        "print(f\"  Target: {TARGET_SPEED} m/s\")\n",
        "print(f\"\\n\ud83c\udfaf Goal: Find optimal FIXED PID parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, SAC, TD3\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def make_env(rank):\n",
        "    def _init():\n",
        "        return FixedPIDEnv(\n",
        "            target_maneuver=TARGET_MANEUVER,\n",
        "            missile_speed=MISSILE_SPEED,\n",
        "            missile_accel=MISSILE_ACCEL,\n",
        "            target_speed=TARGET_SPEED\n",
        "        )\n",
        "    return _init\n",
        "\n",
        "env = DummyVecEnv([make_env(0)])\n",
        "eval_env = DummyVecEnv([make_env(0)])\n",
        "\n",
        "print(\"\u2713 Training environment created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Initialize RL Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_name = f\"FIXED_{ALGORITHM}_{TARGET_MANEUVER}_{timestamp}\"\n",
        "run_dir = f\"/kaggle/working/{run_name}\"\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Deep network architecture\n",
        "policy_kwargs = dict(\n",
        "    net_arch=dict(\n",
        "        pi=[256, 256, 256],\n",
        "        qf=[256, 256, 256]\n",
        "    )\n",
        ")\n",
        "\n",
        "if ALGORITHM == 'SAC':\n",
        "    model = SAC(\n",
        "        'MlpPolicy',\n",
        "        env,\n",
        "        learning_rate=3e-4,\n",
        "        buffer_size=100_000,\n",
        "        learning_starts=1000,\n",
        "        batch_size=256,\n",
        "        tau=0.005,\n",
        "        gamma=0.99,\n",
        "        train_freq=1,\n",
        "        gradient_steps=1,\n",
        "        verbose=1,\n",
        "        tensorboard_log=os.path.join(run_dir, 'tensorboard'),\n",
        "        device='cuda',\n",
        "        policy_kwargs=policy_kwargs\n",
        "    )\n",
        "elif ALGORITHM == 'PPO':\n",
        "    policy_kwargs['net_arch'] = [256, 256, 256]\n",
        "    model = PPO(\n",
        "        'MlpPolicy',\n",
        "        env,\n",
        "        learning_rate=3e-4,\n",
        "        n_steps=2048,\n",
        "        batch_size=64,\n",
        "        verbose=1,\n",
        "        tensorboard_log=os.path.join(run_dir, 'tensorboard'),\n",
        "        device='cuda',\n",
        "        policy_kwargs=policy_kwargs\n",
        "    )\n",
        "\n",
        "print(f\"\u2713 {ALGORITHM} model initialized\")\n",
        "print(f\"\u2713 Output: {run_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Setup Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=25_000,\n",
        "    save_path=os.path.join(run_dir, 'checkpoints'),\n",
        "    name_prefix='model'\n",
        ")\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=os.path.join(run_dir, 'best_model'),\n",
        "    log_path=os.path.join(run_dir, 'eval_logs'),\n",
        "    eval_freq=10_000,\n",
        "    n_eval_episodes=5,\n",
        "    deterministic=True\n",
        ")\n",
        "\n",
        "print(\"\u2713 Callbacks configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train Model \ud83d\ude80\n",
        "\n",
        "Training will take ~20-30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training Fixed PID with {ALGORITHM}\")\n",
        "print(f\"Target: {TARGET_MANEUVER}\")\n",
        "print(f\"Timesteps: {TOTAL_TIMESTEPS:,}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=TOTAL_TIMESTEPS,\n",
        "    callback=[checkpoint_callback, eval_callback],\n",
        "    progress_bar=True\n",
        ")\n",
        "\n",
        "final_path = os.path.join(run_dir, 'final_model')\n",
        "model.save(final_path)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"\u2713 Training complete!\")\n",
        "print(f\"\u2713 Model saved: {final_path}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Extract Optimal PID Parameters \u2b50\n",
        "\n",
        "This is the main output: optimal PID values for the target maneuver!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "best_model_path = os.path.join(run_dir, 'best_model', 'best_model.zip')\n",
        "if ALGORITHM == 'SAC':\n",
        "    eval_model = SAC.load(best_model_path)\n",
        "elif ALGORITHM == 'PPO':\n",
        "    eval_model = PPO.load(best_model_path)\n",
        "\n",
        "# Test and extract PID parameters\n",
        "test_env = FixedPIDEnv(\n",
        "    target_maneuver=TARGET_MANEUVER,\n",
        "    missile_speed=MISSILE_SPEED,\n",
        "    missile_accel=MISSILE_ACCEL,\n",
        "    target_speed=TARGET_SPEED\n",
        ")\n",
        "\n",
        "n_test_episodes = 10\n",
        "hits = 0\n",
        "pid_values = []\n",
        "rewards = []\n",
        "distances = []\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"EXTRACTING OPTIMAL PID PARAMETERS\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for episode in range(n_test_episodes):\n",
        "    obs, _ = test_env.reset()\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action, _ = eval_model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, _, info = test_env.step(action)\n",
        "        episode_reward += reward\n",
        "\n",
        "    rewards.append(episode_reward)\n",
        "    distances.append(info['distance'])\n",
        "    \n",
        "    if info['hit']:\n",
        "        hits += 1\n",
        "    \n",
        "    pid_values.append([info['pid_kp'], info['pid_ki'], info['pid_kd']])\n",
        "    \n",
        "    print(f\"Episode {episode+1}: {'HIT' if info['hit'] else 'MISS':4s} | \"\n",
        "          f\"Dist={info['distance']:6.1f}m | \"\n",
        "          f\"Kp={info['pid_kp']:.3f}, Ki={info['pid_ki']:.3f}, Kd={info['pid_kd']:.3f}\")\n",
        "\n",
        "# Calculate optimal PID values\n",
        "pid_values = np.array(pid_values)\n",
        "optimal_kp = np.mean(pid_values[:, 0])\n",
        "optimal_ki = np.mean(pid_values[:, 1])\n",
        "optimal_kd = np.mean(pid_values[:, 2])\n",
        "std_kp = np.std(pid_values[:, 0])\n",
        "std_ki = np.std(pid_values[:, 1])\n",
        "std_kd = np.std(pid_values[:, 2])\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"OPTIMAL PID PARAMETERS FOR '{TARGET_MANEUVER}' TARGET\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  Kp = {optimal_kp:.3f} \u00b1 {std_kp:.3f}\")\n",
        "print(f\"  Ki = {optimal_ki:.3f} \u00b1 {std_ki:.3f}\")\n",
        "print(f\"  Kd = {optimal_kd:.3f} \u00b1 {std_kd:.3f}\")\n",
        "print(f\"\\n  Hit Rate: {hits}/{n_test_episodes} ({100*hits/n_test_episodes:.1f}%)\")\n",
        "print(f\"  Avg Reward: {np.mean(rewards):.1f}\")\n",
        "print(f\"  Avg Distance: {np.mean(distances):.1f}m\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\\n\ud83d\udca1 Use these values in your missile system:\")\n",
        "print(f\"\\n   missile.set_pid_gains(kp={optimal_kp:.3f}, ki={optimal_ki:.3f}, kd={optimal_kd:.3f})\")\n",
        "print(f\"\\n   Or test in demo.py:\")\n",
        "print(f\"   python demo.py --maneuver {TARGET_MANEUVER} --kp {optimal_kp:.3f} --ki {optimal_ki:.3f} --kd {optimal_kd:.3f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# PID parameters distribution\n",
        "axes[0].hist(pid_values[:, 0], bins=10, alpha=0.7, color='red', edgecolor='black')\n",
        "axes[0].axvline(optimal_kp, color='darkred', linestyle='--', linewidth=2, label=f'Mean: {optimal_kp:.3f}')\n",
        "axes[0].set_xlabel('Kp', fontsize=12)\n",
        "axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0].set_title('Proportional Gain Distribution', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].hist(pid_values[:, 1], bins=10, alpha=0.7, color='green', edgecolor='black')\n",
        "axes[1].axvline(optimal_ki, color='darkgreen', linestyle='--', linewidth=2, label=f'Mean: {optimal_ki:.3f}')\n",
        "axes[1].set_xlabel('Ki', fontsize=12)\n",
        "axes[1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1].set_title('Integral Gain Distribution', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "axes[2].hist(pid_values[:, 2], bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
        "axes[2].axvline(optimal_kd, color='darkblue', linestyle='--', linewidth=2, label=f'Mean: {optimal_kd:.3f}')\n",
        "axes[2].set_xlabel('Kd', fontsize=12)\n",
        "axes[2].set_ylabel('Frequency', fontsize=12)\n",
        "axes[2].set_title('Derivative Gain Distribution', fontweight='bold')\n",
        "axes[2].legend()\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, 'pid_distribution.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\u2713 PID distribution plot saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Download Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Save optimal PID values to text file\n",
        "with open(os.path.join(run_dir, 'optimal_pid.txt'), 'w') as f:\n",
        "    f.write(f\"Optimal PID Parameters for '{TARGET_MANEUVER}' target\\n\")\n",
        "    f.write(f\"=\"*50 + \"\\n\\n\")\n",
        "    f.write(f\"Kp = {optimal_kp:.3f} \u00b1 {std_kp:.3f}\\n\")\n",
        "    f.write(f\"Ki = {optimal_ki:.3f} \u00b1 {std_ki:.3f}\\n\")\n",
        "    f.write(f\"Kd = {optimal_kd:.3f} \u00b1 {std_kd:.3f}\\n\\n\")\n",
        "    f.write(f\"Hit Rate: {hits}/{n_test_episodes} ({100*hits/n_test_episodes:.1f}%)\\n\")\n",
        "    f.write(f\"Avg Reward: {np.mean(rewards):.1f}\\n\")\n",
        "    f.write(f\"Avg Distance: {np.mean(distances):.1f}m\\n\")\n",
        "\n",
        "archive_name = f\"{run_name}_model\"\n",
        "shutil.make_archive(\n",
        "    f\"/kaggle/working/{archive_name}\",\n",
        "    'zip',\n",
        "    run_dir\n",
        ")\n",
        "\n",
        "print(f\"\u2713 Model archived: /kaggle/working/{archive_name}.zip\")\n",
        "print(f\"\ud83d\udce5 Download from Kaggle Output panel\")\n",
        "print(f\"\\nContents:\")\n",
        "print(f\"  - optimal_pid.txt     (Optimal PID values)\")\n",
        "print(f\"  - best_model/         (Trained model)\")\n",
        "print(f\"  - pid_distribution.png (Visualization)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary\n",
        "\n",
        "### What we did:\n",
        "1. \u2705 Set up GPU environment\n",
        "2. \u2705 Defined Fixed PID environment\n",
        "3. \u2705 Trained RL agent to find optimal FIXED PID parameters\n",
        "4. \u2705 Extracted optimal PID values\n",
        "5. \u2705 Visualized results\n",
        "\n",
        "### Key Results:\n",
        "- **Optimal Kp, Ki, Kd** values for your target maneuver\n",
        "- Ready to use in real missile system\n",
        "- Interpretable and practical\n",
        "\n",
        "### Next Steps:\n",
        "1. Test these PID values in `demo.py`\n",
        "2. Try different target maneuvers (straight, zigzag, evasive)\n",
        "3. Compare with hand-tuned PID values\n",
        "4. Deploy in your missile guidance system\n",
        "\n",
        "### Why Fixed PID is Better:\n",
        "- \u2705 Practical: Real systems use fixed PID\n",
        "- \u2705 Interpretable: Clear PID values you can understand\n",
        "- \u2705 Fast: Learns quicker than adaptive approach\n",
        "- \u2705 Testable: Easy to validate and tune further"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}